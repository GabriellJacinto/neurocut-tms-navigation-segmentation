{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D Brain MRI Segmentation with fastai, MONAI, U-Net & ResNet\n",
    "\n",
    "**Supports:**\n",
    "- 3D U-Net (MONAI)\n",
    "- 3D ResNet (MONAI)\n",
    "- fastai training loop, metrics, and augmentations\n",
    "- Single and batch inference\n",
    "\n",
    "**Targets:** cortex (3, 42), M1 (8), DLPFC (5), etc. (see label codes below)\n",
    "\n",
    "---\n",
    "\n",
    "## Dataset & Label Codes\n",
    "- Dataset: IBSR, preprocessed\n",
    "- Label codes: cortex: 3, 42; M1: 8; DLPFC: 5; (add more as needed)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from fastai.vision.all import *\n",
    "from fastai.callback.all import *\n",
    "import monai\n",
    "from monai.networks.nets import UNet, BasicUNet, resnet\n",
    "from monai.transforms import Compose, LoadImaged, EnsureChannelFirstd, Spacingd, Orientationd, ScaleIntensityd, ToTensord\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Codes & Targets\n",
    "\n",
    "```python\n",
    "label_codes = {\n",
    "    'background': 0,\n",
    "    'cortex_left': 3,\n",
    "    'cortex_right': 42,\n",
    "    'M1': 8,\n",
    "    'DLPFC': 5,\n",
    "    # Add more as needed\n",
    "}\n",
    "targets = ['cortex_left', 'cortex_right', 'M1', 'DLPFC']\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_codes = {\n",
    "    'background': 0,\n",
    "    'cortex_left': 3,\n",
    "    'cortex_right': 42,\n",
    "    'M1': 8,\n",
    "    'DLPFC': 5,\n",
    "}\n",
    "targets = ['cortex_left', 'cortex_right', 'M1', 'DLPFC']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading Utilities\n",
    "- Load single or batch 3D MRI images and masks\n",
    "- Use label codes for mask extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nifti(path):\n",
    "    img = nib.load(str(path))\n",
    "    data = img.get_fdata()\n",
    "    return data\n",
    "\n",
    "def extract_target_mask(mask, label_codes, targets):\n",
    "    out = np.zeros_like(mask, dtype=np.uint8)\n",
    "    for i, t in enumerate(targets, 1):\n",
    "        out[np.isin(mask, label_codes[t])] = i\n",
    "    return out\n",
    "\n",
    "def load_image_and_mask(img_path, mask_path, label_codes, targets):\n",
    "    img = load_nifti(img_path)\n",
    "    mask = load_nifti(mask_path)\n",
    "    mask = extract_target_mask(mask, label_codes, targets)\n",
    "    return img, mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "- Z-score normalization\n",
    "- (Optional) N4ITK, histogram equalization, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zscore_normalize(img):\n",
    "    img = img.astype(np.float32)\n",
    "    mean = img.mean()\n",
    "    std = img.std()\n",
    "    return (img - mean) / (std + 1e-8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 images and 4 masks\n"
     ]
    }
   ],
   "source": [
    "IMG_DIR = Path('../data/preprocessed')\n",
    "MASK_DIR = Path('../data/classical_segmented')\n",
    "img_files = sorted(list(IMG_DIR.glob('IBSR_*_zscore.nii.gz')))\n",
    "mask_files = sorted(list(MASK_DIR.glob('IBSR_*_zscore.nii_otsu.nii.gz')))  # or change to _kmeans, _watershed, etc.\n",
    "print(f'Found {len(img_files)} images and {len(mask_files)} masks')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataBlock & Dataloaders (fastai)\n",
    "- Custom get_x, get_y, and transforms for 3D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9dba5487",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import Tensor, show_image\n",
    "\n",
    "def show_3d_tensor(x, ctx=None, title=None, **kwargs):\n",
    "    arr = x\n",
    "    if hasattr(arr, 'cpu'): arr = arr.cpu()\n",
    "    arr = arr.squeeze()\n",
    "    print(f\"Shape to show: {arr.shape}\")  # Debug print\n",
    "\n",
    "    # Handle (D, H, W), (1, D, H, W), (C, D, H, W), (H, W)\n",
    "    if arr.ndim == 3:\n",
    "        # (D, H, W): show middle slice along depth\n",
    "        slice_idx = arr.shape[0] // 2\n",
    "        img = arr[slice_idx]\n",
    "    elif arr.ndim == 4:\n",
    "        # (C, D, H, W): show first channel, middle slice\n",
    "        slice_idx = arr.shape[1] // 2\n",
    "        img = arr[0, slice_idx]\n",
    "    elif arr.ndim == 2:\n",
    "        img = arr\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected tensor shape for 3D image: {arr.shape}\")\n",
    "    return show_image(img, ctx=ctx, title=title, **kwargs)\n",
    "\n",
    "Tensor.show = show_3d_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape to show: torch.Size([256, 256, 128])\n",
      "Shape to show: torch.Size([256, 256, 128])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAK4AAAFICAYAAADJZsXFAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAA5lJREFUeJzt1LsJwwAQBUFLqDWX4CpdgnvzKVPqDwixMBNf8ILllpmZG8SsVw+AfwiXJOGSJFyShEuScEkSLknCJUm4JG3fHt7Xx5k74PB6Pz/e+LgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZK0zMxcPQJ+5eOSJFyShEuScEkSLknCJUm4JAmXJOGStAO+4Q2JJW/LwAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_x(i): return zscore_normalize(load_nifti(img_files[i]))\n",
    "def get_y(i): return extract_target_mask(load_nifti(mask_files[i]), label_codes, targets)\n",
    "\n",
    "class ToTensor3D(Transform):\n",
    "    def encodes(self, x):\n",
    "        t = torch.tensor(x, dtype=torch.float32)\n",
    "        if t.ndim == 3:\n",
    "            t = t.unsqueeze(0)  # (D, H, W) -> (1, D, H, W)\n",
    "        elif t.ndim == 4 and t.shape[0] == 1:\n",
    "            pass  # already (1, D, H, W)\n",
    "        elif t.ndim == 4 and t.shape[-1] == 1:\n",
    "            t = t.permute(3, 0, 1, 2)  # (D, H, W, 1) -> (1, D, H, W)\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected image shape: {t.shape}\")\n",
    "        return t\n",
    "    def decodes(self, x): return x.squeeze()\n",
    "\n",
    "class ToTensorMask3D(Transform):\n",
    "    def encodes(self, x): return torch.tensor(x, dtype=torch.long)\n",
    "    def decodes(self, x): return x\n",
    "\n",
    "dblock = DataBlock(\n",
    "    blocks=(TransformBlock(type_tfms=ToTensor3D()), TransformBlock(type_tfms=ToTensorMask3D())),\n",
    "    get_x=get_x,\n",
    "    get_y=get_y,\n",
    "    splitter=RandomSplitter(seed=42),\n",
    ")\n",
    "dls = dblock.dataloaders(range(len(img_files)), bs=1)\n",
    "dls.show_batch(max_n=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definitions (MONAI)\n",
    "- 3D U-Net\n",
    "- 3D ResNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(targets) + 1  # background + targets\n",
    "\n",
    "unet3d = UNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=n_classes,\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides=(2, 2, 2, 2),\n",
    "   num_res_units=2,\n",
    "    norm='batch'\n",
    "    )\n",
    "\n",
    "resnet3d = resnet.resnet10(spatial_dims=3, n_input_channels=1, num_classes=n_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fastai Learner Setup\n",
    "- Use fastai's Learner for training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "metrics = [DiceMulti(), JaccardCoeffMulti()]  # Use your custom metrics or fastai/monai\n",
    "\n",
    "learn_unet = Learner(dls, unet3d, loss_func=loss_func, metrics=metrics)\n",
    "learn_resnet = Learner(dls, resnet3d, loss_func=loss_func, metrics=metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "- Train both models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00&lt;?]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>dice_multi</th>\n",
       "      <th>jaccard_coeff_multi</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/4 00:00&lt;?]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train U-Net\n",
    "learn_unet.fine_tune(10)\n",
    "# Train ResNet\n",
    "learn_resnet.fine_tune(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference: Single and Batch\n",
    "- Predict on a single image or a batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single(learn, img_path):\n",
    "    img = zscore_normalize(load_nifti(img_path))\n",
    "    img_t = torch.tensor(img, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "    pred = learn.model(img_t.cuda()).argmax(1).cpu().numpy()[0]\n",
    "    return pred\n",
    "\n",
    "def predict_batch(learn, img_paths):\n",
    "    preds = []\n",
    "    for p in img_paths:\n",
    "        preds.append(predict_single(learn, p))\n",
    "    return preds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics & Evaluation\n",
    "- Dice, Jaccard, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Evaluate on validation set\n",
    "val_idxs = dls.valid.items\n",
    "dice_scores = []\n",
    "for i in val_idxs:\n",
    "    img = get_x(i)\n",
    "    mask = get_y(i)\n",
    "    pred = predict_single(learn_unet, img_files[i])\n",
    "    dice = (2 * (pred == mask).sum()) / ((pred > 0).sum() + (mask > 0).sum() + 1e-8)\n",
    "    dice_scores.append(dice)\n",
    "print(f'Mean Dice: {np.mean(dice_scores):.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "- Show slices of input, ground truth, and prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_slices(img, mask, pred, slice_idx=None):\n",
    "    if slice_idx is None:\n",
    "        slice_idx = img.shape[-1] // 2\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    axs[0].imshow(img[..., slice_idx], cmap='gray'); axs[0].set_title('Image')\n",
    "    axs[1].imshow(mask[..., slice_idx]); axs[1].set_title('Mask')\n",
    "    axs[2].imshow(pred[..., slice_idx]); axs[2].set_title('Prediction')\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
