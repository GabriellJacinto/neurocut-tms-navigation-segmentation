{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Segmentation: 3D U-Net Inference\n",
    "\n",
    "This notebook demonstrates how to use a pre-trained 3D U-Net (e.g., from MONAI or nnU-Net) to segment brain MRI volumes.\n",
    "\n",
    "- Loads preprocessed images\n",
    "- Runs inference with a pre-trained model\n",
    "- Saves predicted masks\n",
    "- Computes Dice/Jaccard metrics if ground truth is available\n",
    "- Visualizes results for a single example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from monai.networks.nets import UNet\n",
    "from monai.transforms import Compose, LoadImaged, ScaleIntensityd, ToTensord\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.data import decollate_batch\n",
    "from sklearn.metrics import jaccard_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load a Pre-trained 3D U-Net Model\n",
    "(This example uses MONAI's UNet. Replace with nnU-Net or your own model as needed.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/orion23/Documents/repos/neurocut-tms-navigation-segmentation/.venv/lib/python3.10/site-packages/torch/cuda/__init__.py:129: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "UNet.__init__() got an unexpected keyword argument 'dimensions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Example: create a MONAI UNet and load weights (replace with your checkpoint)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mUNet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdimensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43min_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchannels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_res_units\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# model.load_state_dict(torch.load('path_to_checkpoint.pth', map_location=device))\u001b[39;00m\n\u001b[1;32m     12\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "\u001b[0;31mTypeError\u001b[0m: UNet.__init__() got an unexpected keyword argument 'dimensions'"
     ]
    }
   ],
   "source": [
    "# Example: create a MONAI UNet and load weights (replace with your checkpoint)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = UNet(\n",
    "    dimensions=3,\n",
    "    in_channels=1,\n",
    "    out_channels=2,\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    "    ).to(device)\n",
    "# model.load_state_dict(torch.load('path_to_checkpoint.pth', map_location=device))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Preprocessing and Inference Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img_path):\n",
    "    img = nib.load(str(img_path))\n",
    "    data = img.get_fdata().astype(np.float32)\n",
    "    # Normalize to [0, 1]\n",
    "    data = (data - data.min()) / (data.max() - data.min())\n",
    "    # Add channel and batch dimensions\n",
    "    data = data[None, None, ...]  \n",
    "    # shape: (1, 1, X, Y, Z)\n",
    "    return torch.from_numpy(data).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Inference on a Single Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = Path('../data/preprocessed/IBSR_10_zscore.nii.gz')\n",
    "input_tensor = preprocess_image(img_path)\n",
    "with torch.no_grad():\n",
    "    output = sliding_window_inference(input_tensor, roi_size=(96,96,96), sw_batch_size=1, predictor=model)\n",
    "    pred = torch.argmax(output, dim=1).cpu().numpy()[0]\n",
    "# Save predicted mask\n",
    "    img = nib.load(str(img_path))\n",
    "    nib.save(nib.Nifti1Image(pred.astype(np.uint8), img.affine), 'IBSR_10_unet_pred.nii.gz')\n",
    "# Visualize central slice\n",
    "    slice_idx = pred.shape[2] // 2\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.subplot(1,2,1); plt.imshow(img.get_fdata()[:,:,slice_idx], cmap='gray'); plt.title('Image')\n",
    "    plt.subplot(1,2,2); plt.imshow(pred[:,:,slice_idx], cmap='hot', alpha=0.7); plt.title('Predicted Mask')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compute Dice/Jaccard Metrics (if ground truth available)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_path = Path('../data/subset/IBSR_10/segmentation/analyze/IBSR_10_seg_ana.img')\n",
    "if gt_path.exists():\n",
    "    gt_img = nib.load(str(gt_path))\n",
    "    gt_data = gt_img.get_fdata()\n",
    "    gt_bin = (gt_data > 0)\n",
    "    pred_bin = (pred > 0)\n",
    "    # Dice\n",
    "    intersection = np.logical_and(gt_bin, pred_bin).sum()\n",
    "    dice = 2. * intersection / (gt_bin.sum() + pred_bin.sum())\n",
    "    # Jaccard\n",
    "    jaccard = intersection / np.logical_or(gt_bin, pred_bin).sum()\n",
    "    print(f'Dice: {dice:.3f}, Jaccard: {jaccard:.3f}')\n",
    "else:\n",
    "    print('Ground truth not found.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Batch Inference for All Images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = Path('/home/orion23/Documents/repos/neurocut-tms-navigation-segmentation/data/preprocessed')\n",
    "out_dir = Path('/home/orion23/Documents/repos/neurocut-tms-navigation-segmentation/data/deep_learning_segmented')\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "for img_path in input_dir.glob('*_zscore.nii.gz'):\n",
    "    input_tensor = preprocess_image(img_path)\n",
    "    with torch.no_grad():\n",
    "        output = sliding_window_inference(input_tensor, roi_size=(96,96,96), sw_batch_size=1, predictor=model)\n",
    "        pred = torch.argmax(output, dim=1).cpu().numpy()[0]\n",
    "    img = nib.load(str(img_path))\n",
    "    nib.save(nib.Nifti1Image(pred.astype(np.uint8), img.affine), out_dir / f'{img_path.stem}_unet_pred.nii.gz')\n",
    "    # Optionally compute metrics if ground truth exists\n",
    "    subject = '_'.join(img_path.stem.split('_')[:2])\n",
    "    gt_path = Path(f'/home/orion23/Documents/repos/neurocut-tms-navigation-segmentation/data/subset/{subject}/segmentation/analyze/{subject}_seg_ana.img')\n",
    "    if gt_path.exists():\n",
    "        gt_img = nib.load(str(gt_path))\n",
    "        gt_data = gt_img.get_fdata()\n",
    "        gt_bin = (gt_data > 0)\n",
    "        pred_bin = (pred > 0)\n",
    "        intersection = np.logical_and(gt_bin, pred_bin).sum()\n",
    "        dice = 2. * intersection / (gt_bin.sum() + pred_bin.sum())\n",
    "        jaccard = intersection / np.logical_or(gt_bin, pred_bin).sum()\n",
    "        print(f'{subject}: Dice={dice:.3f}, Jaccard={jaccard:.3f}')\n",
    "    else:\n",
    "        print(f'{subject}: Ground truth not found.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
