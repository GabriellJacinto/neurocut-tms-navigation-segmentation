{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea607570",
   "metadata": {},
   "source": [
    "# 3D Brain MRI Segmentation \n",
    "\n",
    "**Targets:** cortex (3, 42), M1 (8), DLPFC (5).\n",
    "\n",
    "---\n",
    "\n",
    "## Label Codes \n",
    "Label codes: cortex: 3, 42; M1: 8; DLPFC: 5\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3495e515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from fastai.vision.all import *\n",
    "from fastai.callback.all import *\n",
    "import monai\n",
    "from monai.networks.nets import UNet, BasicUNet, resnet\n",
    "from monai.transforms import Compose, LoadImaged, EnsureChannelFirstd, Spacingd, Orientationd, ScaleIntensityd, ToTensord\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef0055a",
   "metadata": {},
   "source": [
    "## Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6eaf94e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_codes = {\n",
    "    'background': 0,\n",
    "    'cortex_left': 3,\n",
    "    'cortex_right': 42,\n",
    "    'M1': 8,\n",
    "    'DLPFC': 5,\n",
    "}\n",
    "targets = ['cortex_left', 'cortex_right', 'M1', 'DLPFC']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547ddfeb",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df0d0377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nifti(path):\n",
    "    img = nib.load(str(path))\n",
    "    data = img.get_fdata()\n",
    "    return data\n",
    "\n",
    "def extract_target_mask(mask, label_codes, targets):\n",
    "    out = np.zeros_like(mask, dtype=np.uint8)\n",
    "    for i, t in enumerate(targets, 1):\n",
    "        out[np.isin(mask, label_codes[t])] = i\n",
    "    return out\n",
    "\n",
    "def load_image_and_mask(img_path, mask_path, label_codes, targets):\n",
    "    img = load_nifti(img_path)\n",
    "    mask = load_nifti(mask_path)\n",
    "    mask = extract_target_mask(mask, label_codes, targets)\n",
    "    return img, mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e095a73",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "- Z-score normalization\n",
    "- N4ITK, histogram equalization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95cc8dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zscore_normalize(img):\n",
    "    img = img.astype(np.float32)\n",
    "    mean = img.mean()\n",
    "    std = img.std()\n",
    "    return (img - mean) / (std + 1e-8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4db9b1e",
   "metadata": {},
   "source": [
    "## Dataset Paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69225b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 images and 4 masks\n"
     ]
    }
   ],
   "source": [
    "IMG_DIR = Path('../data/preprocessed')\n",
    "MASK_DIR = Path('../data/classical_segmented')\n",
    "img_files = sorted(list(IMG_DIR.glob('IBSR_*_zscore.nii.gz')))\n",
    "mask_files = sorted(list(MASK_DIR.glob('IBSR_*_zscore.nii_otsu.nii.gz'))\n",
    "print(f'Found {len(img_files)} images and {len(mask_files)} masks')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e892f608",
   "metadata": {},
   "source": [
    "## DataBlock & Dataloaders (fastai)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9dba5487",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import Tensor, show_image\n",
    "\n",
    "def show_3d_tensor(x, ctx=None, title=None, **kwargs):\n",
    "    arr = x\n",
    "    if hasattr(arr, 'cpu'): arr = arr.cpu()\n",
    "    arr = arr.squeeze()\n",
    "    print(f\"Shape to show: {arr.shape}\") \n",
    "\n",
    "    # Handle (D, H, W), (1, D, H, W), (C, D, H, W), (H, W)\n",
    "    if arr.ndim == 3:\n",
    "        # (D, H, W): show middle slice along depth\n",
    "        slice_idx = arr.shape[0] // 2\n",
    "        img = arr[slice_idx]\n",
    "    elif arr.ndim == 4:\n",
    "        # (C, D, H, W): show first channel, middle slice\n",
    "        slice_idx = arr.shape[1] // 2\n",
    "        img = arr[0, slice_idx]\n",
    "    elif arr.ndim == 2:\n",
    "        img = arr\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected tensor shape for 3D image: {arr.shape}\")\n",
    "    return show_image(img, ctx=ctx, title=title, **kwargs)\n",
    "\n",
    "Tensor.show = show_3d_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b23d2c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape to show: torch.Size([256, 256, 128])\n",
      "Shape to show: torch.Size([256, 256, 128])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAK4AAAFICAYAAADJZsXFAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAA5lJREFUeJzt1LsJwwAQBUFLqDWX4CpdgnvzKVPqDwixMBNf8ILllpmZG8SsVw+AfwiXJOGSJFyShEuScEkSLknCJUm4JG3fHt7Xx5k74PB6Pz/e+LgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZK0zMxcPQJ+5eOSJFyShEuScEkSLknCJUm4JAmXJOGStAO+4Q2JJW/LwAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_x(i): return zscore_normalize(load_nifti(img_files[i]))\n",
    "def get_y(i): return extract_target_mask(load_nifti(mask_files[i]), label_codes, targets)\n",
    "\n",
    "class ToTensor3D(Transform):\n",
    "    def encodes(self, x):\n",
    "        t = torch.tensor(x, dtype=torch.float32)\n",
    "        if t.ndim == 3:\n",
    "            t = t.unsqueeze(0)  # (D, H, W) -> (1, D, H, W)\n",
    "        elif t.ndim == 4 and t.shape[0] == 1:\n",
    "            pass  # already (1, D, H, W)\n",
    "        elif t.ndim == 4 and t.shape[-1] == 1:\n",
    "            t = t.permute(3, 0, 1, 2)  # (D, H, W, 1) -> (1, D, H, W)\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected image shape: {t.shape}\")\n",
    "        return t\n",
    "    def decodes(self, x): return x.squeeze()\n",
    "\n",
    "class ToTensorMask3D(Transform):\n",
    "    def encodes(self, x): return torch.tensor(x, dtype=torch.long)\n",
    "    def decodes(self, x): return x\n",
    "\n",
    "dblock = DataBlock(\n",
    "    blocks=(TransformBlock(type_tfms=ToTensor3D()), TransformBlock(type_tfms=ToTensorMask3D())),\n",
    "    get_x=get_x,\n",
    "    get_y=get_y,\n",
    "    splitter=RandomSplitter(seed=42),\n",
    ")\n",
    "dls = dblock.dataloaders(range(len(img_files)), bs=1)\n",
    "dls.show_batch(max_n=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f0115c",
   "metadata": {},
   "source": [
    "## Model Definitions (MONAI)\n",
    "- 3D U-Net\n",
    "- 3D ResNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f040743",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(targets) + 1  # background + targets\n",
    "\n",
    "unet3d = UNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=n_classes,\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides=(2, 2, 2, 2),\n",
    "   num_res_units=2,\n",
    "    norm='batch'\n",
    "    )\n",
    "\n",
    "resnet3d = resnet.resnet10(spatial_dims=3, n_input_channels=1, num_classes=n_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52d375d",
   "metadata": {},
   "source": [
    "## fastai Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "447eb4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "metrics = [DiceMulti(), JaccardCoeffMulti()]\n",
    "\n",
    "learn_unet = Learner(dls, unet3d, loss_func=loss_func, metrics=metrics)\n",
    "learn_resnet = Learner(dls, resnet3d, loss_func=loss_func, metrics=metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f4e81b",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7d7a54ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00&lt;?]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>dice_multi</th>\n",
       "      <th>jaccard_coeff_multi</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/4 00:00&lt;?]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train U-Net\n",
    "learn_unet.fine_tune(10)\n",
    "# Train ResNet\n",
    "learn_resnet.fine_tune(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe5936c",
   "metadata": {},
   "source": [
    "Im not being able to run this, it is giving me an error on the sizing for some reason. Might have to pivot..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a95a86f",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd71a144",
   "metadata": {},
   "source": [
    "## Metrics & Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41de7102",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
